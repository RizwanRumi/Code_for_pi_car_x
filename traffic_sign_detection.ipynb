{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"traffic_sign_detection.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1U3FSi5LUap_Skak5EuR6T1B2GoYum-kF","authorship_tag":"ABX9TyMmLgsJofndIqsy67qaAg3W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["import os\n","\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/TrafficSignData')\n","\n","#print(os.getcwd())\n"],"metadata":{"id":"zKEZXZ4rcaiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KUhDQsBDadp6"},"outputs":[],"source":["#!git clone https://bitbucket.org/jadslim/german-traffic-signs\n"]},{"cell_type":"code","source":["!ls german-traffic-signs"],"metadata":{"id":"svN5nn2ucrZb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import keras\n","from keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers import Dense\n","from keras.layers import Flatten, Dropout\n","from keras.utils.np_utils import to_categorical\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","import random\n","import pickle\n","import pandas as pd\n","import cv2\n","\n","from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n"," \n","%matplotlib inline\n","np.random.seed(0) "],"metadata":{"id":"vWtCu7wbdqVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load training and validation data\n","with open('german-traffic-signs/train.p', 'rb') as f:\n","    train_data = pickle.load(f)\n","with open('german-traffic-signs/valid.p', 'rb') as f:\n","    val_data = pickle.load(f)\n","# load test data\n","with open('german-traffic-signs/test.p', 'rb') as f:\n","    test_data = pickle.load(f)"],"metadata":{"id":"bLHht042eBbc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#print(train_data)\n","\n","# split out b2n features and labels \n","X_train, y_train = train_data['features'], train_data['labels']\n","#print(X_train.shape)\n","#print(y_train.shape)\n","X_val, y_val = val_data['features'], val_data['labels']\n","#print(X_val.shape)\n","#print(y_val.shape)\n","X_test, y_test = test_data['features'], test_data['labels']\n","#print(X_test.shape)\n","\n","\n","# 4 dimensional data\n","print(X_train.shape)\n","print(X_test.shape)\n","print(X_val.shape)"],"metadata":{"id":"hayVIJBPepp9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code implementation should pass these tests. \n","assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels.\"\n","assert(X_train.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\"\n","assert(X_val.shape[0] == y_val.shape[0]), \"The number of images is not equal to the number of labels.\"\n","assert(X_val.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\"\n","assert(X_test.shape[0] == y_test.shape[0]), \"The number of images is not equal to the number of labels.\"\n","assert(X_test.shape[1:] == (32,32,3)), \"The dimensions of the images are not 32 x 32 x 3.\""],"metadata":{"id":"UQw37Qzoe7XC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('german-traffic-signs/signnames.csv')\n","print(data)"],"metadata":{"id":"ONQyjl-1gxwh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_of_samples = []\n","\n","cols = 5\n","num_of_classes = 43\n","\n","fig, axs = plt.subplots(nrows = num_of_classes, ncols = cols, figsize=(5,50))\n","fig.tight_layout()\n","\n","\n","for i, row in data.iterrows():\n","  for j in range(cols):\n","    x_selected = X_train[y_train == i]\n","    axs[i][j].imshow(x_selected[random.randint(0,(len(x_selected) - 1))])\n","    axs[i][j].axis(\"off\")\n","    if j == 2:\n","      axs[i][j].set_title(str(i) + \" - \" + row[\"SignName\"])\n","      num_of_samples.append(len(x_selected))\n"],"metadata":{"id":"y4EFSjCXjTzg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(num_of_samples)\n","plt.figure(figsize=(12, 4))\n","plt.bar(range(0, num_of_classes), num_of_samples)\n","plt.title(\"Distribution of the train dataset\")\n","plt.xlabel(\"Class number\")\n","plt.ylabel(\"Number of images\")\n","plt.show()"],"metadata":{"id":"cjdtc8nwhrtq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n"," \n","plt.imshow(X_train[1000])\n","plt.axis(\"off\")\n","print(X_train[1000].shape)\n","print(y_train[1000])\n","\n"],"metadata":{"id":"rasznJcFqkok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def grayscale(img):\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    return img\n","\n","img = grayscale(X_train[1000])\n","plt.imshow(img)\n","plt.axis(\"off\")\n","print(img.shape)\n"],"metadata":{"id":"78Gn296srktB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def equalize(img):\n","    img = cv2.equalizeHist(img)\n","    return img\n","img = equalize(img)\n","plt.imshow(img)\n","plt.axis(\"off\")\n","print(img.shape)\n","\n"],"metadata":{"id":"ypLk9W31tS_6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(img):\n","    img = grayscale(img)\n","    img = equalize(img)\n","    img = img/255\n","    return img"],"metadata":{"id":"4RMKK9aDtq4o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = np.array(list(map(preprocess, X_train)))\n","X_test = np.array(list(map(preprocess, X_test)))\n","X_val = np.array(list(map(preprocess, X_val)))\n"," \n","plt.imshow(X_train[random.randint(0, len(X_train) - 1)])\n","plt.axis('off')\n","print(X_train.shape)"],"metadata":{"id":"iwir0shhtofz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = X_train.reshape(34799, 32, 32, 1)\n","X_test = X_test.reshape(12630, 32, 32, 1)\n","X_val = X_val.reshape(4410, 32, 32, 1)"],"metadata":{"id":"NjK5_ejLt_3g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n"," \n","datagen = ImageDataGenerator(width_shift_range=0.1,\n","                            height_shift_range=0.1,\n","                            zoom_range=0.2,\n","                            shear_range=0.1,\n","                            rotation_range=10.)\n"," \n","datagen.fit(X_train)\n","# for X_batch, y_batch in\n"," \n","batches = datagen.flow(X_train, y_train, batch_size = 15)\n","X_batch, y_batch = next(batches)\n"," \n","fig, axs = plt.subplots(1, 15, figsize=(20, 5))\n","fig.tight_layout()\n"," \n","for i in range(15):\n","    axs[i].imshow(X_batch[i].reshape(32, 32))\n","    axs[i].axis(\"off\")\n"," \n","print(X_batch.shape)\n"],"metadata":{"id":"4KZJwFO8uKTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = to_categorical(y_train, 43)\n","y_test = to_categorical(y_test, 43)\n","y_val = to_categorical(y_val, 43)\n"],"metadata":{"id":"s7DlIC9JuQwA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create model\n"," \n","def modified_model():\n","  model = Sequential()\n","  model.add(Conv2D(60, (5, 5), input_shape=(32, 32, 1), activation='relu'))\n","  model.add(Conv2D(60, (5, 5), activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  \n","  model.add(Conv2D(30, (3, 3), activation='relu'))\n","  model.add(Conv2D(30, (3, 3), activation='relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","  #model.add(Dropout(0.5))\n","\n","  model.add(Flatten())\n","  model.add(Dense(500, activation='relu'))\n","  model.add(Dropout(0.5))\n","  model.add(Dense(43, activation='softmax'))\n","  \n","  model.compile(Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","  return model"],"metadata":{"id":"qHkmHwxrxyjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = modified_model()\n","print(model.summary())"],"metadata":{"id":"VjRSIR_yuWsa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(datagen.flow(X_train, y_train, batch_size=30), \n","                              steps_per_epoch=X_train.shape[0]/50,\n","                              epochs=20,\n","                              validation_data=(X_val, y_val), shuffle = 1)"],"metadata":{"id":"L6LpYltswNOp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Loss')\n","plt.xlabel('epoch')"],"metadata":{"id":"cRLRJG1_uvIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.legend(['training','test'])\n","plt.title('Accuracy')\n","plt.xlabel('epoch')"],"metadata":{"id":"B-SPGLy5vBmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Evaluate model on test data\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"XKDOh6H8vGeV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#predict internet number\n","import requests\n","from PIL import Image\n","\n","#url = 'https://c8.alamy.com/comp/G667W0/road-sign-speed-limit-30-kmh-zone-passau-bavaria-germany-G667W0.jpg'\n","#url = 'https://c8.alamy.com/comp/A0RX23/cars-and-automobiles-must-turn-left-ahead-sign-A0RX23.jpg'\n","#url = 'https://previews.123rf.com/images/bwylezich/bwylezich1608/bwylezich160800375/64914157-german-road-sign-slippery-road.jpg'\n","#url = 'https://previews.123rf.com/images/pejo/pejo0907/pejo090700003/5155701-german-traffic-sign-no-205-give-way.jpg'\n","url = 'https://c8.alamy.com/comp/J2MRAJ/german-road-sign-bicycles-crossing-J2MRAJ.jpg'\n","\n","r = requests.get(url, stream=True)\n","img = Image.open(r.raw)\n","plt.imshow(img, cmap=plt.get_cmap('gray'))"],"metadata":{"id":"fN0BcaUHvJFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = np.asarray(img)\n","img = cv2.resize(img, (32, 32))\n","img = preprocess(img)\n","plt.imshow(img, cmap = plt.get_cmap('gray'))\n","print(img.shape)\n","img = img.reshape(1, 32, 32, 1)\n","\n","predict = model.predict(img)\n","prdict_index = np.argmax(predict)\n","\n","print(\"predicted sign: \"+ str(data['SignName'][prdict_index]))"],"metadata":{"id":"GI3c6mve-rBo"},"execution_count":null,"outputs":[]}]}